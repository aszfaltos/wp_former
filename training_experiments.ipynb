{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c29d49-35c0-426e-a5ba-3c1273947d4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:56:21.588305307Z",
     "start_time": "2024-01-30T15:56:18.183597403Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from data_handling.data_loader import load_mavir_data\n",
    "from trainer_lib import Grid, transformer_grid_search, TrainerOptions, GridSearchOptions\n",
    "from models import Transformer\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dee256-92d0-44f9-bdc1-c5a5416d347f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:56:22.839708507Z",
     "start_time": "2024-01-30T15:56:21.597787466Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_mavir_data('data/mavir_data/mavir.csv')\n",
    "df['Power'] = utils.min_max_norm(df['Power'])\n",
    "sample = utils.sample(df, 5000, start_idx=0)\n",
    "\n",
    "# imfs, residue = utils.apply_eemd(sample['Power'].to_numpy(), spline_kind='akima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002f67f4-272a-4c38-8547-2698b67defce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:56:22.860466693Z",
     "start_time": "2024-01-30T15:56:22.850214572Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = np.array(sample['Power'].to_numpy()[...,np.newaxis], dtype=np.float32)\n",
    "# training_data_decomp = np.array(np.c_[imfs.transpose(), residue[...,np.newaxis]], dtype=np.float32)\n",
    "# training_data_decomp_rem = np.array(np.c_[imfs[1:].transpose(), residue[...,np.newaxis]], dtype=np.float32)\n",
    "# training_data_combined = np.array(np.c_[sample['Power'].to_numpy()[...,np.newaxis], imfs.transpose(), residue[...,np.newaxis]], dtype=np.float32)\n",
    "# training_data_combined_rem = np.array(np.c_[sample['Power'].to_numpy()[...,np.newaxis], imfs[1:].transpose(), residue[...,np.newaxis]], dtype=np.float32)\n",
    "# print(training_data.shape)\n",
    "# print(training_data.dtype)\n",
    "# print(training_data_decomp.shape)\n",
    "# print(training_data_decomp.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc320372-d6ea-492f-8a07-7638c6e948cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:59:51.666865772Z",
     "start_time": "2024-01-30T15:56:22.863267389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 981, Validation size: 245\n",
      "Epoch: 1; Learning rate: [1.0000090000000002e-05]; Train - MSE: 1.6198442498358292; Eval - MSE: 1.375135604412325, RMSE: 1.1698223876868619, MAE: 1.1401000695843848, MAPE: 1.7430111002032154\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 2; Learning rate: [2.0000080000000004e-05]; Train - MSE: 1.2470769828897184; Eval - MSE: 0.231626127756411, RMSE: 0.47710820384691816, MAE: 0.4209099979169907, MAPE: 0.6470923845253022\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 3; Learning rate: [3.000007000000001e-05]; Train - MSE: 0.5387142442348531; Eval - MSE: 0.2847975055056234, RMSE: 0.5250039394404606, MAE: 0.45712650687463824, MAPE: 0.676776083546002\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 4; Learning rate: [4.000006000000001e-05]; Train - MSE: 0.5247753731664119; Eval - MSE: 0.1987481867113421, RMSE: 0.43613749143966335, MAE: 0.35645473339865286, MAPE: 0.5248547409385735\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 5; Learning rate: [5.0000050000000006e-05]; Train - MSE: 0.41380701907645395; Eval - MSE: 0.08079832999576485, RMSE: 0.2755480322833249, MAE: 0.22134802802916495, MAPE: 0.32128800890489473\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 6; Learning rate: [6.000004000000001e-05]; Train - MSE: 0.36902515323666074; Eval - MSE: 0.11166237348750713, RMSE: 0.32414323756324814, MAE: 0.24821772522503324, MAPE: 0.36156967264042583\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 7; Learning rate: [7.000003000000001e-05]; Train - MSE: 0.33027472141070074; Eval - MSE: 0.07802957975335661, RMSE: 0.26975838257657914, MAE: 0.20699305447839922, MAPE: 0.3003057414758894\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 8; Learning rate: [8.000002000000002e-05]; Train - MSE: 0.31009128423241095; Eval - MSE: 0.12170966384151288, RMSE: 0.34107076073681486, MAE: 0.2817306643532168, MAPE: 0.41605794806304763\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 9; Learning rate: [9.000001000000002e-05]; Train - MSE: 0.31291368549189896; Eval - MSE: 0.14374796829877362, RMSE: 0.3739493940880328, MAE: 0.3359405537766795, MAPE: 0.5012310876326361\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aszfalt/Documents/projects/wp_former/venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10; Learning rate: [0.0001]; Train - MSE: 0.25072620563754217; Eval - MSE: 0.0882181819648512, RMSE: 0.293912947885276, MAE: 0.27225491404533386, MAPE: 0.4085922823573557\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 11; Learning rate: [9.900000000000001e-05]; Train - MSE: 0.2170159412108787; Eval - MSE: 0.06177007166608687, RMSE: 0.24560112442230458, MAE: 0.22092972695827484, MAPE: 0.33733100894721324\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 12; Learning rate: [9.801e-05]; Train - MSE: 0.18963919122650363; Eval - MSE: 0.12190686358559517, RMSE: 0.34532467178993076, MAE: 0.30477214628650295, MAPE: 0.46951591020439143\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 13; Learning rate: [9.70299e-05]; Train - MSE: 0.17372562751416273; Eval - MSE: 0.04544945013138555, RMSE: 0.21020193238336593, MAE: 0.18530190567816457, MAPE: 0.2876332571083627\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 14; Learning rate: [9.605960100000001e-05]; Train - MSE: 0.16794327861530997; Eval - MSE: 0.018355921992371158, RMSE: 0.13243979803592956, MAE: 0.11364054776007129, MAPE: 0.178411121069577\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 15; Learning rate: [9.509900499000001e-05]; Train - MSE: 0.16355778626734163; Eval - MSE: 0.08909732127381911, RMSE: 0.2957607848205451, MAE: 0.2718803603802958, MAPE: 0.4164281912431084\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 16; Learning rate: [9.414801494010001e-05]; Train - MSE: 0.1368545611366266; Eval - MSE: 0.14569823948606367, RMSE: 0.3787613030462708, MAE: 0.3474448698182261, MAPE: 0.5320811210599568\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 17; Learning rate: [9.320653479069902e-05]; Train - MSE: 0.1392052054738368; Eval - MSE: 0.061959344172669996, RMSE: 0.2460852147475331, MAE: 0.216247935929606, MAPE: 0.33451224630193654\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 18; Learning rate: [9.227446944279203e-05]; Train - MSE: 0.14379687778409425; Eval - MSE: 0.07704688212083233, RMSE: 0.27447110050452556, MAE: 0.23688138925260113, MAPE: 0.36586893633529344\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 19; Learning rate: [9.13517247483641e-05]; Train - MSE: 0.12933415410722174; Eval - MSE: 0.09047763878780025, RMSE: 0.2979246892283052, MAE: 0.26287884048877225, MAPE: 0.40599557913780815\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Stopped after 19 epochs.\n",
      "Train size: 981, Validation size: 245\n",
      "Epoch: 1; Learning rate: [1.0000090000000002e-05]; Train - MSE: 2.779280861218772; Eval - MSE: 2.2807323394283174, RMSE: 1.506388423115017, MAE: 1.4824403947399507, MAPE: 2.2690357781397075\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 2; Learning rate: [2.0000080000000004e-05]; Train - MSE: 2.2331041858448253; Eval - MSE: 0.7819710950697621, RMSE: 0.8773425984331447, MAE: 0.8354717050829243, MAPE: 1.2681219524201595\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 3; Learning rate: [3.000007000000001e-05]; Train - MSE: 0.9564742656742653; Eval - MSE: 0.11186435578330868, RMSE: 0.33198346199080603, MAE: 0.2961599999858487, MAPE: 0.46095671891675655\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 4; Learning rate: [4.000006000000001e-05]; Train - MSE: 0.48565859608049294; Eval - MSE: 0.6529679654106016, RMSE: 0.8036720418874311, MAE: 0.7555882103981509, MAPE: 1.1926220231187687\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 5; Learning rate: [5.0000050000000006e-05]; Train - MSE: 0.4847701764930555; Eval - MSE: 0.3741517816820452, RMSE: 0.6070393897426073, MAE: 0.5450426609285416, MAPE: 0.8662243246356663\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 6; Learning rate: [6.000004000000001e-05]; Train - MSE: 0.41437089403833804; Eval - MSE: 0.19489565756051766, RMSE: 0.43739572611678046, MAE: 0.39027878257536125, MAPE: 0.6182405304458138\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 7; Learning rate: [7.000003000000001e-05]; Train - MSE: 0.3459192103123278; Eval - MSE: 0.27347781725468173, RMSE: 0.5185330758283376, MAE: 0.46204602141534123, MAPE: 0.7358376773302947\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 8; Learning rate: [8.000002000000002e-05]; Train - MSE: 0.3064090440852371; Eval - MSE: 0.30487614918139677, RMSE: 0.5478364658897922, MAE: 0.4901946946497887, MAPE: 0.7795410852398806\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Stopped after 8 epochs.\n",
      "Train size: 962, Validation size: 240\n",
      "Epoch: 1; Learning rate: [1.0000090000000002e-05]; Train - MSE: 0.3848660823481141; Eval - MSE: 0.07231373867640893, RMSE: 0.2640713896352874, MAE: 0.2310170436898867, MAPE: 0.34630511901687633\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 2; Learning rate: [2.0000080000000004e-05]; Train - MSE: 0.3897725467470068; Eval - MSE: 0.08176611214876173, RMSE: 0.28161547711093815, MAE: 0.25081041132410364, MAPE: 0.37274570042401656\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 3; Learning rate: [3.000007000000001e-05]; Train - MSE: 0.3912200167282554; Eval - MSE: 0.07043636577824752, RMSE: 0.2611358471564596, MAE: 0.2306928510467211, MAPE: 0.3449254714445112\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n",
      "Epoch: 4; Learning rate: [4.000006000000001e-05]; Train - MSE: 0.36097886810494856; Eval - MSE: 0.07678378093987703, RMSE: 0.27284618055660026, MAE: 0.24364316115776702, MAPE: 0.36073640982231187\n",
      "<class 'float'> <class 'float'> <class 'float'> <class 'float'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 40\u001B[0m\n\u001B[1;32m     18\u001B[0m training_opts \u001B[38;5;241m=\u001B[39m TrainerOptions(\n\u001B[1;32m     19\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[1;32m     20\u001B[0m     epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     29\u001B[0m     save_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     32\u001B[0m grid_search_opts \u001B[38;5;241m=\u001B[39m GridSearchOptions(\n\u001B[1;32m     33\u001B[0m     root_save_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./trained/regular/\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     34\u001B[0m     valid_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m     use_start_token\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     38\u001B[0m )\n\u001B[0;32m---> 40\u001B[0m models \u001B[38;5;241m=\u001B[39m \u001B[43mtransformer_grid_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_opts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrid_search_opts\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/projects/wp_former/trainer_lib/grid_search.py:63\u001B[0m, in \u001B[0;36mtransformer_grid_search\u001B[0;34m(grid, data, trainer_options, opts)\u001B[0m\n\u001B[1;32m     60\u001B[0m     trainer_options\u001B[38;5;241m.\u001B[39msave_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, names[idx])\n\u001B[1;32m     61\u001B[0m     trainer \u001B[38;5;241m=\u001B[39m Trainer(model, trainer_options)\n\u001B[0;32m---> 63\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m     models\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m: names[idx],\n\u001B[1;32m     65\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m: trainer\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[1;32m     66\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: params,\n\u001B[1;32m     67\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetrics\u001B[39m\u001B[38;5;124m'\u001B[39m: trainer\u001B[38;5;241m.\u001B[39mmetrics})\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m models\n",
      "File \u001B[0;32m~/Documents/projects/wp_former/trainer_lib/trainer.py:64\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, train_data, valid_data)\u001B[0m\n\u001B[1;32m     62\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(loss\u001B[38;5;241m.\u001B[39mitem()) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[1;32m     63\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopts\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps\n\u001B[0;32m---> 64\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((batch_idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopts\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \\\n\u001B[1;32m     67\u001B[0m         (batch_idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)):\n\u001B[1;32m     68\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Documents/projects/wp_former/venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/projects/wp_former/venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'src_size' : [1],\n",
    "    'tgt_size' : [1],\n",
    "    'd_model' : [256], #, 256, 512],\n",
    "    'num_heads' : [2], # , 4, 8],\n",
    "    'num_layers' : [2], # , 2, 3],\n",
    "    'd_ff' : [512, 1024], # , 1024, 2048],\n",
    "    'src_seq_length' : [24], # , 96],\n",
    "    'tgt_seq_length' : [1],\n",
    "    'src_window': [4, 8],\n",
    "    'tgt_window': [1],\n",
    "    'dropout' : [0.2], # , 0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "grid = Grid(params)\n",
    "names = utils.generate_name(len(grid), 42)\n",
    "\n",
    "training_opts = TrainerOptions(\n",
    "    batch_size=8,\n",
    "    epochs=30,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_steps=10,\n",
    "    warmup_start_factor=1e-6,\n",
    "    gradient_accumulation_steps=8,\n",
    "    early_stopping_patience=5,\n",
    "    early_stopping_min_delta=0.01,\n",
    "    save_every_n_epochs=1,\n",
    "    save_path=''\n",
    ")\n",
    "\n",
    "grid_search_opts = GridSearchOptions(\n",
    "    root_save_path='./trained/regular/',\n",
    "    valid_split=0.2,\n",
    "    window_step_size=4,\n",
    "    random_seed=42,\n",
    "    use_start_token=True\n",
    ")\n",
    "\n",
    "models = transformer_grid_search(grid, training_data, training_opts, grid_search_opts)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0af9384-1b44-487b-ac11-c616b6f0c865",
   "metadata": {},
   "source": [
    "params = {\n",
    "'src_size' : [11],\n",
    "'tgt_size' : [11],\n",
    "'d_model' : [128], #, 256, 512],\n",
    "'num_heads' : [2], # , 4, 8],\n",
    "'num_layers' : [1], # , 2, 3],\n",
    "'d_ff' : [512], # , 1024, 2048],\n",
    "'enc_seq_length' : [72], # , 96],\n",
    "'dec_seq_length' : [24],\n",
    "'dropout' : [0.2], # , 0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "grid = Grid(params)\n",
    "\n",
    "models_decomp = grid_search(grid, Transformer, training_data_decomp, training_data_decomp, epochs=20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "633cafa0-bff5-4132-8852-bba4f1772378",
   "metadata": {},
   "source": [
    "params = {\n",
    "'src_size' : [12],\n",
    "'tgt_size' : [1],\n",
    "'d_model' : [128], #, 256, 512],\n",
    "'num_heads' : [2], # , 4, 8],\n",
    "'num_layers' : [1], # , 2, 3],\n",
    "'d_ff' : [512], # , 1024, 2048],\n",
    "'enc_seq_length' : [72], # , 96],\n",
    "'dec_seq_length' : [24],\n",
    "'dropout' : [0.2], # , 0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "grid = Grid(params)\n",
    "\n",
    "models_decomp_combined = grid_search(grid, Transformer, training_data_combined, training_data, epochs=20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b014c52a-2490-43bb-a418-0e802c903943",
   "metadata": {},
   "source": [
    "params = {\n",
    "'src_size' : [11],\n",
    "'tgt_size' : [1],\n",
    "'d_model' : [128], #, 256, 512],\n",
    "'num_heads' : [2], # , 4, 8],\n",
    "'num_layers' : [1], # , 2, 3],\n",
    "'d_ff' : [512], # , 1024, 2048],\n",
    "'enc_seq_length' : [72], # , 96],\n",
    "'dec_seq_length' : [24],\n",
    "'dropout' : [0.2], # , 0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "grid = Grid(params)\n",
    "\n",
    "models_decomp_combined_rem = grid_search(grid, Transformer, training_data_combined_rem, training_data, epochs=20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c1de78a-c276-45f7-9b50-c12c29510d35",
   "metadata": {},
   "source": [
    "params = {\n",
    "'src_size' : [10],\n",
    "'tgt_size' : [10],\n",
    "'d_model' : [128], #, 256, 512],\n",
    "'num_heads' : [2], # , 4, 8],\n",
    "'num_layers' : [1], # , 2, 3],\n",
    "'d_ff' : [512], # , 1024, 2048],\n",
    "'enc_seq_length' : [72], # , 96],\n",
    "'dec_seq_length' : [24],\n",
    "'dropout' : [0.2], # , 0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "grid = Grid(params)\n",
    "\n",
    "models_decomp_rem = grid_search(grid, Transformer, training_data_decomp_rem, training_data_decomp_rem, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9fc5f-cf20-477a-a64c-a7ebc35536b0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:59:51.656097772Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#for model in models_decomp_combined:\n",
    "#    plt.plot(model['metrics']['eval_loss'], label=f'{model[\"name\"]} - {model[\"params\"][\"enc_seq_length\"]} - combined')\n",
    "\n",
    "#for model in models_decomp_combined_rem:\n",
    "#    plt.plot(model['metrics']['eval_loss'], label=f'{model[\"name\"]} - {model[\"params\"][\"enc_seq_length\"]} - combined rem')\n",
    "\n",
    "#for model in models_decomp_rem:\n",
    "#    plt.plot(model['metrics']['eval_loss'], label=f'{model[\"name\"]} - {model[\"params\"][\"enc_seq_length\"]} - rem')\n",
    "\n",
    "#for model in models_decomp:\n",
    "#    plt.plot(model['metrics']['eval_loss'], label=f'{model[\"name\"]} - {model[\"params\"][\"enc_seq_length\"]} - decomp')\n",
    "max_len = 0\n",
    "for model in models:\n",
    "    plt.plot(model['metrics']['eval']['MSE'], label=f'{model[\"name\"]} - {model[\"params\"][\"src_seq_length\"]} - normal - eval')\n",
    "    plt.plot(np.arange(len(model['metrics']['train']['MSE'])), model['metrics']['train']['MSE'], label=f'{model[\"name\"]} - {model[\"params\"][\"src_seq_length\"]} - normal - train')\n",
    "    max_len = max(len(model['metrics']['eval']['MSE']), max_len)\n",
    "    max_len = max(len(model['metrics']['train']['MSE']), max_len)\n",
    "\n",
    "plt.xticks(np.arange(max_len))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('mse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bc098-3a4a-493b-90a1-ba731694b264",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:59:51.656609439Z"
    }
   },
   "outputs": [],
   "source": [
    "from trainer_lib.datasets import TimeSeriesWindowedTensorDataset, TimeSeriesWindowedDatasetConfig\n",
    "\n",
    "shift, look_back, pred = 50, 24, 1\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    model['model'].eval()\n",
    "    dataset = TimeSeriesWindowedTensorDataset(training_data, TimeSeriesWindowedDatasetConfig(model['params']['src_window'], \n",
    "                                                                                             model['params']['tgt_window'], \n",
    "                                                                                             model['params']['src_seq_length'], \n",
    "                                                                                             model['params']['tgt_seq_length'], \n",
    "                                                                                             1, \n",
    "                                                                                             False))\n",
    "    ones = torch.ones(1, 1, dataset[0][1].shape[-1])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        ground_truth = []\n",
    "        predicted = []\n",
    "        for shift_offset in range(shift, shift+24, 1):\n",
    "            out = ones\n",
    "            for i in range(pred):\n",
    "                out = torch.concatenate((ones, model['model'](dataset[shift_offset][0].unsqueeze(0), out)), dim=1)\n",
    "        \n",
    "            predicted.append(dataset.get_sequence_from_y_windows(out[:, 1:, :].detach()))\n",
    "            ground_truth.append(dataset.get_sequence_from_y_windows(dataset[shift_offset][1]))\n",
    "    \n",
    "    predicted = np.array(predicted).reshape(24)\n",
    "    ground_truth = np.array(ground_truth).reshape(24)\n",
    "    plt.plot(ground_truth, label='ground truth')\n",
    "    plt.plot(predicted, label='24h rolling one step')\n",
    "    \n",
    "    #output = model['model'](\n",
    "    #    dataset[shift][0].unsqueeze(0),  \n",
    "    #    torch.concat((ones, dataset[shift][1][:-1, :].unsqueeze(0)), dim=1)\n",
    "    #)\n",
    "    #\n",
    "    #plt.plot(torch.concat(\n",
    "    #    (dataset.get_sequence_from_x_windows(dataset[shift][0]), \n",
    "    #     dataset.get_sequence_from_y_windows(dataset[shift][1])), dim=0), label='original')\n",
    "    #plt.plot(\n",
    "    #    torch.concatenate(\n",
    "    #        (dataset.get_sequence_from_x_windows(dataset[shift][0]),\n",
    "    #         dataset.get_sequence_from_y_windows(output[:, :, :].detach())), dim=0), \n",
    "    #    label='full access - normal'\n",
    "    #)\n",
    "    #plt.plot(\n",
    "    #    torch.concatenate(\n",
    "    #        (dataset.get_sequence_from_x_windows(dataset[shift][0]), \n",
    "    #         dataset.get_sequence_from_y_windows(out[:, 1:, :].detach())), dim=0),\n",
    "    #    label='predicted - normal'\n",
    "    #)\n",
    "    \n",
    "#for model in models_decomp:\n",
    "#    out = torch.ones(1,1,11)\n",
    "#    for _ in range(25):\n",
    "#        output = model['model'](torch.tensor(training_data_decomp[np.newaxis, 0:72,:]), out)# torch.tensor(training_data[np.newaxis, 73:97,:]))# torch.zeros((1, 24, 1)))\n",
    "#        out = torch.concatenate((out, output[:,-1,:].unsqueeze(1)), axis=1)\n",
    "#    plt.plot(out[:, 1:-1, :].detach().reshape((24,11)).sum(-1), label='predicted - decomp')\n",
    "\n",
    "#for model in models_decomp_rem:\n",
    "#    out = torch.ones(1,1,10)\n",
    "#    for _ in range(25):\n",
    "#        output = model['model'](torch.tensor(training_data_decomp_rem[np.newaxis, 0:72,:]), out)# torch.tensor(training_data[np.newaxis, 73:97,:]))# torch.zeros((1, 24, 1)))\n",
    "#        out = torch.concatenate((out, output[:,-1,:].unsqueeze(1)), axis=1)\n",
    "#    plt.plot(out[:, 1:-1, :].detach().reshape((24,10)).sum(-1), label='predicted - rem')\n",
    "\n",
    "#for model in models_decomp_combined:\n",
    "#    out = torch.ones(1,1,1)\n",
    "#    for _ in range(25):\n",
    "#        output = model['model'](torch.tensor(training_data_combined[np.newaxis, 0:72,:]), out)# torch.tensor(training_data[np.newaxis, 73:97,:]))# torch.zeros((1, 24, 1)))\n",
    "#        out = torch.concatenate((out, output[:,-1,:].unsqueeze(1)), axis=1)\n",
    "#    plt.plot(out[:, 1:-1, :].detach().reshape((24,)), label='predicted - combined')\n",
    "\n",
    "#for model in models_decomp_combined_rem:\n",
    "#    out = torch.ones(1,1,1)\n",
    "#    for _ in range(25):\n",
    "#        output = model['model'](torch.tensor(training_data_combined_rem[np.newaxis, 0:72,:]), out)# torch.tensor(training_data[np.newaxis, 73:97,:]))# torch.zeros((1, 24, 1)))\n",
    "#        out = torch.concatenate((out, output[:,-1,:].unsqueeze(1)), axis=1)\n",
    "#    plt.plot(out[:, 1:-1, :].detach().reshape((24,)), label='predicted - combined rem')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a5eb4-a47c-4078-b5d2-fc73ab2d42a2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:59:51.656873155Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
